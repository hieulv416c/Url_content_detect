{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hieulv416c/Url_content_detect/blob/main/Doc2vec%2BMLnew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntmmLi-oAzWw"
      },
      "outputs": [],
      "source": [
        "!pip install catboost\n",
        "!pip install --upgrade gensim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import re\n",
        "import unicodedata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from tqdm import tqdm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "l32ht7NEi1yb",
        "outputId": "14dacdfa-8c93-4d3c-b825-c4b81b812cd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hu·∫•n luy·ªán Doc2Vec...\n",
            "‚è≥ Th·ªùi gian hu·∫•n luy·ªán Doc2Vec: 1546.95 gi√¢y\n"
          ]
        }
      ],
      "source": [
        "# Load d·ªØ li·ªáu\n",
        "df = pd.read_csv(\"/content/content_cleaned.csv\")\n",
        "df[\"Content\"] = df[\"Content\"].astype(str)\n",
        "\n",
        "# Chia t·∫≠p d·ªØ li·ªáu\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[\"Content\"].fillna(\"\"), df[\"result\"].fillna(0), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# G√°n nh√£n cho d·ªØ li·ªáu ƒë·ªÉ hu·∫•n luy·ªán Doc2Vec\n",
        "train_tagged = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(X_train)]\n",
        "test_tagged = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(X_test)]\n",
        "\n",
        "# Kh·ªüi t·∫°o m√¥ h√¨nh Doc2Vec tr∆∞·ªõc khi build_vocab\n",
        "doc2vec_model = Doc2Vec(vector_size=100, window=5, min_count=2, workers=4, epochs=20)\n",
        "\n",
        "# ƒêo th·ªùi gian hu·∫•n luy·ªán Doc2Vec\n",
        "start_doc2vec_time = time.time()\n",
        "\n",
        "print(\"Hu·∫•n luy·ªán Doc2Vec...\")\n",
        "doc2vec_model.build_vocab(train_tagged)\n",
        "doc2vec_model.train(train_tagged, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
        "\n",
        "end_doc2vec_time = time.time()\n",
        "doc2vec_training_time = end_doc2vec_time - start_doc2vec_time\n",
        "\n",
        "print(f\"‚è≥ Th·ªùi gian hu·∫•n luy·ªán Doc2Vec: {doc2vec_training_time:.2f} gi√¢y\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPjHLe-Qi5Oi"
      },
      "outputs": [],
      "source": [
        "# Chuy·ªÉn vƒÉn b·∫£n th√†nh vector\n",
        "def vectorize_doc2vec(model, tagged_docs):\n",
        "    return np.array([model.infer_vector(doc.words) for doc in tagged_docs])\n",
        "\n",
        "X_train_vec = vectorize_doc2vec(doc2vec_model, train_tagged)\n",
        "X_test_vec = vectorize_doc2vec(doc2vec_model, test_tagged)\n",
        "\n",
        "# Danh s√°ch c√°c m√¥ h√¨nh c·∫ßn th·ª≠ nghi·ªám (tr·ª´ Random Forest, SVM, Logistic Regression)\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"SVM\": SVC(kernel=\"linear\", probability=True),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=300)\n",
        "}\n",
        "# H√†m hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh\n",
        "def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
        "    start_train_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    end_train_time = time.time()\n",
        "\n",
        "    start_eval_time = time.time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    end_eval_time = time.time()\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\")\n",
        "\n",
        "    print(f\"Accuracy: {acc:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1:.4f}\")\n",
        "    print(f\"Th·ªùi gian hu·∫•n luy·ªán: {end_train_time - start_train_time:.2f} gi√¢y\")\n",
        "    print(f\"Th·ªùi gian ƒë√°nh gi√°: {end_eval_time - start_eval_time:.2f} gi√¢y\\n\")\n",
        "\n",
        "# Ch·∫°y th·ª≠ nghi·ªám v·ªõi c√°c m√¥ h√¨nh\n",
        "for name, model in models.items():\n",
        "    print(f\"üöÄ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh: {name}\")\n",
        "    train_and_evaluate(model, X_train_vec, y_train, X_test_vec, y_test)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNSKDVFUezD0mPkMqAhniFi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}